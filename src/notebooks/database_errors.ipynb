{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3579bd6c-89b9-4440-a85e-4bc5122fae95",
   "metadata": {},
   "source": [
    "Notebook to generate data issues"
   ]
  },
  {
   "cell_type": "code",
   "id": "f6897533-e4f8-4490-b0a8-5e929b1e8ee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T19:33:52.864264Z",
     "start_time": "2025-03-13T19:33:52.852329Z"
    }
   },
   "source": [
    "# 1 missing_columns => one or some of the csv files are missing a required column.\n",
    "# 2 missing_values => one or more values in a row are nulls.\n",
    "# 3 unknown_categorical_values => expected value \"dinner\", \"lunch\", new value: \"drinks\".\n",
    "# 4 unknown_numeric_values => wrong value for a feature, e.g:-1 for tips.\n",
    "# 5 bad_data_type_values => string value in a numerical column and vice versa.\n",
    "# 6 bad_csv_encoding => having unreadable character in CSV file e.g: √†, √π, √ñ, √ú.\n",
    "# 7 bad_delimiter => one or some csv files are seperated by other delimiter e.g: TSV using \\t.\n",
    "# 8 missing_header => one or more header are missing."
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148c16e67fd82a0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T13:36:03.110322Z",
     "start_time": "2025-02-26T13:36:00.279949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tips   sex  smoker day    time  size\n",
      "0  16.99  1.01  Female  No  Dinner     2\n",
      "1  10.34  1.66    Male  No  Dinner     3\n",
      "2  21.01  3.50    Male  No  Dinner     3\n",
      "3  23.68  3.31    Male  No   Lunch     2\n",
      "4  24.59  3.61  Female  No   Lunch     4\n",
      "\n",
      "   total_bill  tips     sex  smoker  day    time size\n",
      "0       16.99  1.01  Female   False  Sat  Dinner  two\n",
      "1       10.34   NaN    Male   False  Sat   Lunch    3\n",
      "2      -21.01  3.50    Male    True  Sun   Lunch    3\n",
      "3       23.68  3.31    M√§le    True  Sun  Dinner  200\n",
      "4       24.59  3.61  Female    True  Mon  Drinks    4\n",
      "\n",
      "  total_bill\\ttip\\tsex\\tsmoker\\t\\ttime\\tsize\n",
      "0    16.99\\t1.01\\tFem√¶le\\tNo\\tSun\\tDinner\\t2\n",
      "1      10.34\\t1.66\\tMale\\tNo\\tSun\\tDinner\\t3\n",
      "2       21.01\\t3.5\\tM√†le\\tNo\\tSun\\tDinner\\t3\n",
      "3      23.68\\t3.31\\tMale\\tNo\\tSun\\tDinner\\t2\n",
      "4    24.59\\t3.61\\tFemale\\tNo\\tSun\\tDinner\\t4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data2 = {\n",
    "    \"total_bill\": [16.99, 10.34, -21.01, 23.68, 24.59],\n",
    "    \"tips\": [1.01, None, 3.5, 3.31, 3.61],\n",
    "    \"sex\": [\"Female\", \"Male\", \"Male\", \"M√§le\", \"Female\"],\n",
    "    \"smoker\": [False, False, True, True, True],\n",
    "    \"day\": [\"Sat\", \"Sat\", \"Sun\", \"Sun\", \"Mon\"],\n",
    "    \"time\": [\"Dinner\", \"Lunch\", \"Lunch\", \"Dinner\", \"Drinks\"],\n",
    "    \"size\": [\"two\", 3, 3, 200, 4],\n",
    "}\n",
    "\n",
    "df_missing_column = pd.read_csv(\n",
    "    \"../../tests/resources/test_folder_1/db_errors_test_folder/test_missing_column.csv\"\n",
    ")\n",
    "df_error2 = pd.DataFrame(data2)\n",
    "df_bad_csv = pd.read_csv(\n",
    "    \"../../tests/resources/test_folder_1/db_errors_test_folder/test_bad_csv_errors.csv\"\n",
    ")\n",
    "print(df_missing_column)\n",
    "print()\n",
    "print(df_error2)\n",
    "print()\n",
    "print(df_bad_csv)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T20:10:19.721374Z",
     "start_time": "2025-03-02T20:10:19.714899Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "# set up empty error dict\n",
    "empty_errors = {\n",
    "    \"missing_header\": None,\n",
    "    \"bad_delimiter\": None,\n",
    "    \"bad_csv_encoding\": None,\n",
    "    \"missing_columns\": None,\n",
    "    \"missing_values\": None,\n",
    "    \"unknown_categorical_values\": None,\n",
    "    \"unknown_numeric_values\": None,\n",
    "    \"bad_data_type_values\": None,\n",
    "}"
   ],
   "id": "d7f99c30ff1ae507"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_delimiter(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        header_line = file.readline().strip()\n",
    "    delimiters = [\",\", \"\\t\", \";\", \"|\", \" \"]\n",
    "    delimiter_counts = {d: header_line.count(d) for d in delimiters}\n",
    "    detected_delimiter = max(delimiter_counts, key=delimiter_counts.get)\n",
    "    return detected_delimiter"
   ],
   "id": "dc65a554c1caba66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_missing_headers(filepath, delimiter = \",\"):\n",
    "    expected_headers = [\"total_bill\", \"tip\", \"sex\", \"smoker\", \"day\", \"time\", \"size\"]\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        header_line = file.readline().strip()\n",
    "    detected_headers = [h.strip() for h in header_line.split(delimiter)]\n",
    "    missing_headers = list(set(expected_headers) - set(detected_headers))\n",
    "    return missing_headers"
   ],
   "id": "b6469bf6d55281dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_missing_columns(filepath, delimiter = \",\"):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        header_line = file.readline().strip()\n",
    "        data_line = file.readline().strip()\n",
    "    num_columns = len(data_line.split(delimiter))\n",
    "    if num_columns < 7:\n",
    "        return \"Missing columns, need manual inspect\""
   ],
   "id": "e35dee50c5d2f0c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:52:26.346251Z",
     "start_time": "2025-03-14T00:52:26.338924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_bad_encode(filepath, d='\\t'):\n",
    "    df = pd.read_csv(filepath, sep=d)\n",
    "    bad_encode_values = {}\n",
    "    for col in df.columns:\n",
    "        rows = []\n",
    "        for index, value in df[col].items():\n",
    "            try:\n",
    "                value.encode('utf-8')\n",
    "            except AttributeError:\n",
    "                value = str(value)\n",
    "            except UnicodeEncodeError:\n",
    "                rows.append(index)\n",
    "        if rows:\n",
    "            bad_encode_values[col] = rows\n",
    "    return bad_encode_values"
   ],
   "id": "16f55330b0c314a4",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:52:37.011768Z",
     "start_time": "2025-03-14T00:52:36.995074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(check_bad_encode(\"../../tests/resources/test_folder_1/db_errors_test_folder/test_bad_csv_errors.csv\"))\n",
    "df3 = pd.read_csv(\"../../tests/resources/test_folder_1/db_errors_test_folder/test_bad_csv_errors.csv\")\n",
    "print(df3)"
   ],
   "id": "457c30d34c8c741b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "  total_bill\\ttip\\tsex\\tsmoker\\t\\ttime\\tsize\n",
      "0    16.99\\t1.01\\tFem√¶le\\tNo\\tSun\\tDinner\\t2\n",
      "1      10.34\\t1.66\\tMale\\tN√∂\\tSun\\tDinner\\t3\n",
      "2       21.01\\t3.5\\tMÔÅÆle\\tNo\\tSun\\tDinner\\t3\n",
      "3    23.68\\t3.31\\tMale\\tNo\\tSun\\t∆≥»§—ß·ñØƒáùó±·ªÖùëì\\t2\n",
      "4    24.59\\t3.61\\tFemale\\tNo\\tSun\\tDinner\\t4\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:36:24.949040Z",
     "start_time": "2025-03-14T00:36:24.939962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def check_missing_value(filepath, d = \",\"):\n",
    "    missing_values = []\n",
    "    df = pd.read_csv(filepath, sep = d)\n",
    "    if df.isnull().values.any():\n",
    "        (rows,cols) = np.where(pd.isnull(df))\n",
    "        if rows.any():\n",
    "            for i in range (len(rows)):\n",
    "                missing_values.append((rows[i], cols[i]))\n",
    "    return missing_values"
   ],
   "id": "44232a00fc75089c",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:36:26.391201Z",
     "start_time": "2025-03-14T00:36:26.377612Z"
    }
   },
   "cell_type": "code",
   "source": "print(check_missing_value(\"../../tests/resources/test_folder_1/db_errors_test_folder/test_missing_values.csv\"))",
   "id": "dee67cfccfc466f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4), (1, 0), (3, 1), (4, 5)]\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:29:13.487526Z",
     "start_time": "2025-03-14T00:29:13.405244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_unknown_numeric_values(filepath, d = \",\"):\n",
    "    numeric_columns = [\"total_bill\", \"tip\", \"size\"]\n",
    "    negative_values = {}\n",
    "    df = pd.read_csv(filepath, sep = d)\n",
    "    for col in numeric_columns:\n",
    "        if df[df[col] < 0 ].values.any():\n",
    "            negative_values[col] = df[df[col] < 0 ].index.tolist()\n",
    "    return negative_values"
   ],
   "id": "830f37aebb86f2e8",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:29:15.833230Z",
     "start_time": "2025-03-14T00:29:15.768106Z"
    }
   },
   "cell_type": "code",
   "source": "print(check_unknown_numeric_values(\"../../tests/resources/test_folder_1/db_errors_test_folder/test_unknow_cat_num_values.csv\"))",
   "id": "efb45a8baa4dd4a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_bill': [3], 'tip': [1]}\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdbbde65f7ff13d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T21:04:31.742206Z",
     "start_time": "2025-03-02T21:04:31.666403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'missing_header': ['day'], 'bad_csv_format': '\\t', 'bad_csv_encoding': None, 'missing_columns': None, 'missing_values': None, 'unknown_categorical_values': None, 'unknown_numeric_values': None, 'bad_data_type_values': None}\n"
     ]
    }
   ],
   "source": [
    "#Ignore\n",
    "#\n",
    "#\n",
    "# check if csv file have errors (missing header or bad delimiter)\n",
    "def check_csv_error(filepath):\n",
    "    errors = empty_errors\n",
    "    expected_headers = [\"total_bill\", \"tip\", \"sex\", \"smoker\", \"day\", \"time\", \"size\"]\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        header_line = file.readline().strip()\n",
    "        data_line = file.readline().strip()\n",
    "    delimiters = [\",\", \"\\t\", \";\", \"|\", \" \"]\n",
    "    delimiter_counts = {d: header_line.count(d) for d in delimiters}\n",
    "    detected_delimiter = max(delimiter_counts, key=delimiter_counts.get)\n",
    "    detected_headers = [h.strip() for h in header_line.split(detected_delimiter)]\n",
    "    missing_headers = list(set(expected_headers) - set(detected_headers))\n",
    "    # bad delimiter checker\n",
    "    if detected_delimiter != \",\":\n",
    "        errors[\"bad_delimiter\"] = detected_delimiter\n",
    "    # missing column and header checker\n",
    "    if missing_headers:\n",
    "        data_columns = data_line.split(detected_delimiter)\n",
    "        num_columns = max(len(detected_headers), len(data_columns))\n",
    "        if num_columns < 7:\n",
    "            errors[\"missing_columns\"] = 7 - num_columns\n",
    "            # idk if to stop in cases this severe and manually deal with it or just continue to detect errors\n",
    "        else:\n",
    "            errors[\"missing_header\"] = missing_headers\n",
    "    ########################\n",
    "    # check encoding\n",
    "    ########################\n",
    "    ########################\n",
    "    # start checking for data problems\n",
    "    # may separate check errors code here, since delimiter is now detected\n",
    "    df = pd.read_csv(file, delimiter=detected_delimiter)\n",
    "    # check how many values are missing\n",
    "    if df.isnull().values.any():\n",
    "        amount_missing = df.isnull().sum().sum()\n",
    "        errors[\"missing_values\"] = amount_missing\n",
    "    ########\n",
    "    # unknown_categorical_values seem to need comparison with a standard\n",
    "    # https://www.kaggle.com/code/manishkc06/handling-unknown-categories-in-dataset\n",
    "    ########\n",
    "    # bad_data_type_values, unknown_numeric_values: check next block\n",
    "    return errors\n",
    "\n",
    "\n",
    "print(\n",
    "    check_csv_error(\n",
    "        \"../../tests/resources/test_folder_1/db_errors_test_folder/test_bad_csv_errors.csv\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "id": "a41b8a3493cbbae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T23:00:20.850518Z",
     "start_time": "2025-03-13T23:00:20.842177Z"
    }
   },
   "source": [
    "# check for bad_data_type_values\n",
    "def check_bad_type_values(filepath, d = ','):\n",
    "    expected_types = {\n",
    "        \"total_bill\": float,\n",
    "        \"tip\": float,\n",
    "        \"sex\": str,\n",
    "        \"smoker\": str,\n",
    "        \"day\": str,\n",
    "        \"time\": str,\n",
    "        \"size\": int,\n",
    "    }\n",
    "    df = pd.read_csv(filepath, sep = d)\n",
    "    bad_type_values = {}\n",
    "    for col, expected_type in expected_types.items():\n",
    "        if expected_type == int:\n",
    "            bad_type_values[col] = df.loc[\n",
    "                ~df[col].astype(str).str.match(r\"^-?\\d+$\", na=False), col\n",
    "            ].index.tolist()\n",
    "        elif expected_type == float:\n",
    "            bad_type_values[col] = df.loc[\n",
    "                ~df[col].astype(str).str.match(r\"^-?\\d+(\\.\\d+)?$\", na=False), col\n",
    "            ].index.tolist()\n",
    "        elif expected_type == str:\n",
    "            bad_type_values[col] = df.loc[\n",
    "                df[col].astype(str).str.match(r\"^-?\\d+(\\.\\d+)?$\", na=False), col\n",
    "            ].index.tolist()\n",
    "\n",
    "    bad_type_values = {col: vals for col, vals in bad_type_values.items() if vals}\n",
    "    return bad_type_values"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "2a754beb1c9231e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T23:01:06.037840Z",
     "start_time": "2025-03-13T23:01:05.971228Z"
    }
   },
   "source": [
    "print(check_bad_type_values(\n",
    "    \"../../tests/resources/test_folder_1/db_errors_test_folder/test_bad_data_type.csv\"\n",
    "))\n",
    "df = pd.read_csv(\"../../tests/resources/test_folder_1/db_errors_test_folder/test_bad_data_type.csv\")\n",
    "print(df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tip': [2], 'sex': [3], 'smoker': [1, 3, 4], 'day': [0], 'size': [0]}\n",
      "   total_bill    tip     sex smoker  day    time size\n",
      "0       16.99   1.01  Female     No    7  Dinner  two\n",
      "1       10.34   1.66    Male      0  Sun  Dinner    3\n",
      "2       21.01  three    Male     No  Sun  Dinner    3\n",
      "3       23.68   3.31       1      1  Sun  Dinner    2\n",
      "4       24.59   3.61  Female      1  Sun  Dinner    4\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:23:00.162044Z",
     "start_time": "2025-03-14T00:23:00.133784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for unknown_categorical_values\n",
    "def check_unknown_categorical_values(filepath, d = \",\"):\n",
    "    expected_categories = {\n",
    "        \"sex\": {\"Female\", \"Male\"},\n",
    "        \"smoker\": {\"Yes\", \"No\"},\n",
    "        \"day\": {\"Sun\", \"Sat\", \"Fri\", \"Thur\", \"Wed\", \"Tue\", \"Mon\"},\n",
    "        \"time\": {\"Lunch\", \"Dinner\"},\n",
    "    }\n",
    "\n",
    "    df = pd.read_csv(filepath, sep = d)\n",
    "    unknown_cat_values = {}\n",
    "\n",
    "    for col, expected_set in expected_categories.items():\n",
    "        if col in df:\n",
    "            bad_rows = df[~df[col].astype(str).isin(expected_set)]\n",
    "            if not bad_rows.empty:\n",
    "                unknown_cat_values[col] = bad_rows.index.tolist()  # Store row indices\n",
    "\n",
    "    return unknown_cat_values"
   ],
   "id": "5304d0cc1931f67d",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T00:24:08.672644Z",
     "start_time": "2025-03-14T00:24:08.622471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(check_unknown_categorical_values(\"../../tests/resources/test_folder_1/db_errors_test_folder/test_unknow_cat_num_values.csv\"))\n",
    "df1 = pd.read_csv(\"../../tests/resources/test_folder_1/db_errors_test_folder/test_unknow_cat_num_values.csv\")\n",
    "print(df1)"
   ],
   "id": "aeb1ef0b3a316698",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': [4], 'smoker': [4], 'time': [1]}\n",
      "   total_bill   tip         sex smoker  day    time  size\n",
      "0       16.99  1.01      Female     No  Sun  Dinner     2\n",
      "1       10.34 -1.66        Male     No  Sun  Drinks     3\n",
      "2       21.01  3.50        Male     No  Sun  Dinner   300\n",
      "3      -23.68  3.31        Male     No  Sun   Lunch     2\n",
      "4       24.59  3.61  Non-binary      1  Sun   Lunch     4\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "144c4023044217c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T23:04:14.860988Z",
     "start_time": "2025-03-13T23:04:14.047657Z"
    }
   },
   "source": [
    "# code to test before putting into checkers\n",
    "# currently: check bad value type\n",
    "df = pd.read_csv(\n",
    "    \"../../tests/resources/test_folder_1/db_errors_test_folder/test_bad_data_type.csv\"\n",
    ")\n",
    "print(df)\n",
    "df.head()\n",
    "df.loc[~df[\"size\"].str.isdigit(), \"size\"].tolist()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill    tip     sex smoker  day    time size\n",
      "0       16.99   1.01  Female     No    7  Dinner  two\n",
      "1       10.34   1.66    Male      0  Sun  Dinner    3\n",
      "2       21.01  three    Male     No  Sun  Dinner    3\n",
      "3       23.68   3.31       1      1  Sun  Dinner    2\n",
      "4       24.59   3.61  Female      1  Sun  Dinner    4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['two']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
